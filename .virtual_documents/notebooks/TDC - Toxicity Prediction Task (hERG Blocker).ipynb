import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from glob import glob
import pickle as pkl

from rdkit import Chem
from rdkit.Chem import rdMolDescriptors, Draw

from tdc.single_pred import Tox

from scripts.load_dataset import DataDownloader
from scripts.clean_transform_data import DataProcessor
from scripts.exploratory_analysis import ExploratoryDataAnalysis
from scripts.train_evaluate_model import DatasetProcessor, Modelling
from scripts.feature_engineering import Featurizer

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)
pd.set_option('display.float_format', lambda x: '%.2f' % x)

import warnings
warnings.filterwarnings("ignore")

%matplotlib inline





# while True:
#     dataset_name = input("Dataset name (AMES or hERG): ").strip()
#     if dataset_name in ["AMES", "hERG"]:
#         break
#     print("Invalid input. Please enter either 'AMES' or 'hERG'.")

dataset_name = "hERG"
downloader = DataDownloader()
df, splits = None, None


# while True:
#     use_existing_data = input("Use Existing Data? (Y/N): ").strip()
#     if use_existing_data in ["Y", "N"]:
#         break
#     print("Invalid input. Please enter either 'Y' or 'N'.")

use_existing_data = 'Y'


if use_existing_data == 'N':
    print("\nDownloading data...")
    df, splits = downloader.fetch_dataset(name = dataset_name)
else:
    print("\nLoading existing data...")
    try:
        df = pd.read_csv(f'../data/{dataset_name}/{dataset_name}.csv')
        train = pd.read_csv(f'../data/{dataset_name}/train.csv') 
        validation = pd.read_csv(f'../data/{dataset_name}/validation.csv') 
        test = pd.read_csv(f'../data/{dataset_name}/test.csv') 
        splits = {"train": train, "validation": validation, "test": test}
        print("Data successfully loaded.")
    except FileNotFoundError as e:
        print(f"Error: {e}. Dataset not found, attempting to download...")
        df, splits = downloader.fetch_dataset(name = dataset_name)


splits.keys()


split_files = [f"../data/{dataset_name}/{key}.csv" for key in splits.keys()] #train, test and split
split_files


for file in split_files:
    processor = DataProcessor(input_csv = file, output_csv = file)
    processor.process_csv()


train.head()





explore = ExploratoryDataAnalysis(dataset_name)
explore.generate_eda()





smiles_list = df["Drug"].iloc[:6].tolist()  # First 6 SMILES
drug_names = df["Drug_ID"].iloc[:6].tolist()  # Their Names

mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]
Draw.MolsToGridImage(mols, molsPerRow = 3, subImgSize=(300, 300), legends=drug_names)





featuriser = "eos5guo" 
!ersilia fetch $featuriser





count = len(glob(f"../data/{dataset_name}/*{featuriser}_featurized*"))
files = ['train', 'test', 'validation']

print("\nPerforming Featurisation...")
if count == 3:
    print("\nData has already by Featurised...")
else:
    featurizer = Featurizer(model_id = featuriser)
    
    for file in files:
        output_path = featurizer.featurize(input_file = file, dataset_name = dataset_name)








#featuriser = 'eos2gw4'
data = 'new_dataset'

modelling = Modelling(dataset_name = dataset_name)
modelling.apply_trained_model(data, featuriser)





splits = list(splits.keys()) #['train', 'test', 'validation']
data_processing = DatasetProcessor(dataset_name = dataset_name, splits = splits, featuriser = featuriser)
modelling = Modelling(dataset_name = dataset_name)


(X_train, y_train, 
     X_test, y_test, 
     X_val, y_val, 
     X_train_smote, y_train_smote, 
     X_train_over, y_train_over, 
     X_train_hybrid, y_train_hybrid)= data_processing.preprocess_and_resample()

train_sets, configs = modelling.model_config(X_train, y_train, 
                                             X_train_over, y_train_over, 
                                             X_train_smote, y_train_smote, 
                                             X_train_hybrid, y_train_hybrid)


model_results = {}

for train_set_name, (X_train, y_train) in train_sets.items(): 
    print(f"Training on dataset: {train_set_name}")

    for config in configs:
        print(f"Current Configuration: {dict(config)}")
        
        model, model_result = modelling.train_model(
            'randomforest',
            X_train, y_train, X_test, y_test, X_val, y_val,
            class_weight=config["class_weight"], 
            use_stratified_kfold=config["use_stratified_kfold"],
            use_gridsearch=config["use_gridsearch"]
        )

        model_results[model] = model_result

    print()  # Blank line for better readability in output



model, model_result = modelling.evaluate_model(model_results)


modelling.visualize_model(model, model_result, "ErG 2D Descriptors (Best Model)", y_test)


with open("../models/best_erg2d_model.pkl", "wb") as f:
    pkl.dump(model, f)
print("Model Saved")





featuriser = 'eos2gw4'
data_processing = DatasetProcessor(dataset_name = dataset_name, splits = splits, featuriser = featuriser)
modelling = Modelling(dataset_name = dataset_name)
(X_train, y_train, 
     X_test, y_test, 
     X_val, y_val, 
     X_train_smote, y_train_smote, 
     X_train_over, y_train_over,
    X_train_hybrid, y_train_hybrid)= data_processing.preprocess_and_resample()

train_sets, configs = modelling.model_config(X_train, y_train, 
                                             X_train_over, y_train_over, 
                                             X_train_smote, y_train_smote,
                                             X_train_hybrid, y_train_hybrid)


model_results = {}

for train_set_name, (X_train, y_train) in train_sets.items(): 
    print(f"Training on dataset: {train_set_name}")

    for config in configs:
        print(f"Current Configuration: {dict(config)}")
        
        model, model_result = modelling.train_model(
            'randomforest',
            X_train, y_train, X_test, y_test, X_val, y_val,
            class_weight = config["class_weight"], 
            use_stratified_kfold=config["use_stratified_kfold"],
            use_gridsearch=config["use_gridsearch"]
        )

        model_results[model] = model_result

    print()  # Blank line for better readability in output

# GridSearchCV: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}


model_performance = {}

for model, results in model_results.items():
    test_metrics = results["test_metrics"]
    tn, fp, fn, tp = test_metrics["confusion_matrix"]

    # Calculate Specificity and NPV
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    npv = tn / (tn + fn) if (tn + fn) > 0 else 0

    # Store the results
    model_performance[model] = {
        "specificity": specificity,
        "npv": npv,
        **test_metrics,  # Include original test metrics
    }

# Convert to DataFrame for easy sorting
df = pd.DataFrame.from_dict(model_performance, orient="index")

# Sort by NPV in descending order
df_sorted = df.sort_values(by="npv", ascending=False)

# Display results
print(df_sorted)


model, model_result = modelling.evaluate_model(model_results)


modelling.visualize_model(model, model_result, "Ersilia Compound Embeddings (Best Model)", y_test)


with open("../models/best_erg2d_model.pkl", "wb") as f:
    pkl.dump(model, f)
print("Mode")


with open("../models/best_erg2d_model.pkl", "rb") as f:
    model = pkl.load(f)


model.predict_proba(X_test)






